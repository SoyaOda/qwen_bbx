#!/usr/bin/env python
"""
Nutrition5k ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
Google Cloud Storage (GCS) ã‹ã‚‰ Nutrition5k ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚
"""

import os
import subprocess
import sys
import argparse
from pathlib import Path
import time
from typing import Optional, List


class Nutrition5kDownloader:
    """Nutrition5k ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, output_dir: str = "nutrition5k_dataset", use_tar: bool = False):
        """
        Args:
            output_dir: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            use_tar: True ã®å ´åˆã€tar.gz ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆ181.4GBï¼‰
                     False ã®å ´åˆã€rsync ã§åŒæœŸï¼ˆæ¨å¥¨ï¼‰
        """
        self.output_dir = Path(output_dir)
        self.use_tar = use_tar
        self.gcs_bucket = "gs://nutrition5k_dataset/nutrition5k_dataset"
        self.gcs_tar = "gs://nutrition5k_dataset/nutrition5k_dataset.tar.gz"
        
    def check_gcloud_installed(self) -> bool:
        """gcloud CLI ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª"""
        try:
            result = subprocess.run(["gcloud", "--version"], 
                                  capture_output=True, text=True)
            print("âœ“ gcloud CLI ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ")
            print(f"  ãƒãƒ¼ã‚¸ãƒ§ãƒ³: {result.stdout.split()[0]}")
            return True
        except FileNotFoundError:
            print("âœ— gcloud CLI ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return False
            
    def check_gsutil_installed(self) -> bool:
        """gsutil ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª"""
        try:
            result = subprocess.run(["gsutil", "version"], 
                                  capture_output=True, text=True)
            print("âœ“ gsutil ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ")
            return True
        except FileNotFoundError:
            print("âœ— gsutil ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return False
            
    def setup_output_directory(self):
        """å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ"""
        self.output_dir.mkdir(parents=True, exist_ok=True)
        print(f"\nâœ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æº–å‚™ã—ã¾ã—ãŸ: {self.output_dir.absolute()}")
        
    def check_disk_space(self) -> bool:
        """ååˆ†ãªãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ãŒã‚ã‚‹ã‹ç¢ºèªï¼ˆæœ€ä½200GBï¼‰"""
        import shutil
        stat = shutil.disk_usage(self.output_dir)
        free_gb = stat.free / (1024 ** 3)
        
        print(f"\nğŸ“Š ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ãƒã‚§ãƒƒã‚¯:")
        print(f"  ç©ºãå®¹é‡: {free_gb:.1f} GB")
        
        required_gb = 200 if not self.use_tar else 400  # tar.gz ã®å ´åˆã¯å±•é–‹åˆ†ã‚‚å¿…è¦
        if free_gb < required_gb:
            print(f"  âš ï¸  è­¦å‘Š: {required_gb}GB ä»¥ä¸Šã®ç©ºãå®¹é‡ãŒæ¨å¥¨ã•ã‚Œã¾ã™")
            return False
        else:
            print(f"  âœ“ ååˆ†ãªç©ºãå®¹é‡ãŒã‚ã‚Šã¾ã™")
            return True
            
    def download_with_rsync(self) -> bool:
        """rsync ã‚’ä½¿ç”¨ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’åŒæœŸï¼ˆæ¨å¥¨æ–¹æ³•ï¼‰"""
        print("\nğŸ“¥ rsync ã§ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
        print(f"  ã‚½ãƒ¼ã‚¹: {self.gcs_bucket}")
        print(f"  ä¿å­˜å…ˆ: {self.output_dir}")
        print("  â€» åˆå›ã¯æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ï¼ˆç´„180GBï¼‰\n")
        
        # gcloud storage rsync ã‚’ä½¿ç”¨ï¼ˆæ–°æ¨å¥¨ï¼‰
        cmd = [
            "gcloud", "storage", "rsync", "-r",
            self.gcs_bucket,
            str(self.output_dir)
        ]
        
        try:
            process = subprocess.Popen(cmd, stdout=subprocess.PIPE, 
                                     stderr=subprocess.STDOUT, 
                                     text=True, bufsize=1)
            
            # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§å‡ºåŠ›ã‚’è¡¨ç¤º
            for line in iter(process.stdout.readline, ''):
                if line:
                    print(f"  {line.strip()}")
                    
            process.wait()
            
            if process.returncode == 0:
                print("\nâœ“ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†ï¼")
                return True
            else:
                print(f"\nâœ— ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼ (code: {process.returncode})")
                return False
                
        except Exception as e:
            print(f"\nâœ— ã‚¨ãƒ©ãƒ¼: {e}")
            return False
            
    def download_tar_gz(self) -> bool:
        """tar.gz ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆä»£æ›¿æ–¹æ³•ï¼‰"""
        print("\nğŸ“¥ tar.gz ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
        print(f"  ã‚½ãƒ¼ã‚¹: {self.gcs_tar}")
        print(f"  ä¿å­˜å…ˆ: {self.output_dir}")
        print("  â€» 181.4GB ã®ãƒ•ã‚¡ã‚¤ãƒ«ã§ã™\n")
        
        tar_path = self.output_dir / "nutrition5k_dataset.tar.gz"
        
        cmd = [
            "gcloud", "storage", "cp",
            self.gcs_tar,
            str(tar_path)
        ]
        
        try:
            process = subprocess.Popen(cmd, stdout=subprocess.PIPE, 
                                     stderr=subprocess.STDOUT, 
                                     text=True, bufsize=1)
            
            for line in iter(process.stdout.readline, ''):
                if line:
                    print(f"  {line.strip()}")
                    
            process.wait()
            
            if process.returncode == 0:
                print("\nâœ“ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†ï¼")
                print("\nğŸ“¦ tar.gz ã‚’å±•é–‹ä¸­...")
                
                # å±•é–‹
                extract_cmd = ["tar", "-xzf", str(tar_path), "-C", str(self.output_dir)]
                subprocess.run(extract_cmd, check=True)
                
                print("âœ“ å±•é–‹å®Œäº†ï¼")
                
                # tar.gz ã‚’å‰Šé™¤ã™ã‚‹ã‹ç¢ºèª
                response = input("\ntar.gz ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã™ã‹ï¼Ÿ (y/n): ")
                if response.lower() == 'y':
                    tar_path.unlink()
                    print("âœ“ tar.gz ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
                    
                return True
            else:
                print(f"\nâœ— ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼ (code: {process.returncode})")
                return False
                
        except Exception as e:
            print(f"\nâœ— ã‚¨ãƒ©ãƒ¼: {e}")
            return False
            
    def verify_dataset(self):
        """ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ§‹æˆã‚’ç¢ºèª"""
        print("\nğŸ” ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ§‹æˆã‚’ç¢ºèªä¸­...")
        
        expected_dirs = [
            "imagery/side_angles",
            "imagery/realsense_overhead", 
            "metadata",
            "dish_ids/splits",
            "scripts"
        ]
        
        for dir_path in expected_dirs:
            full_path = self.output_dir / dir_path
            if full_path.exists():
                print(f"  âœ“ {dir_path}")
            else:
                print(f"  âœ— {dir_path} (è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“)")
                
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º
        metadata_dir = self.output_dir / "metadata"
        if metadata_dir.exists():
            csv_files = list(metadata_dir.glob("*.csv"))[:3]
            if csv_files:
                print(f"\nğŸ“‹ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ä¾‹:")
                for csv_file in csv_files:
                    print(f"  - {csv_file.name}")
                    
    def download_subset(self, components: List[str]):
        """ç‰¹å®šã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®ã¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
        print(f"\nğŸ“¥ é¸æŠã•ã‚ŒãŸã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­: {', '.join(components)}")
        
        for component in components:
            if component == "metadata":
                src = f"{self.gcs_bucket}/metadata"
                dst = self.output_dir / "metadata"
            elif component == "overhead":
                src = f"{self.gcs_bucket}/imagery/realsense_overhead"  
                dst = self.output_dir / "imagery" / "realsense_overhead"
            elif component == "side_angles":
                src = f"{self.gcs_bucket}/imagery/side_angles"
                dst = self.output_dir / "imagery" / "side_angles"
            elif component == "splits":
                src = f"{self.gcs_bucket}/dish_ids/splits"
                dst = self.output_dir / "dish_ids" / "splits"
            else:
                print(f"  âš ï¸  ä¸æ˜ãªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ: {component}")
                continue
                
            dst.parent.mkdir(parents=True, exist_ok=True)
            
            cmd = ["gcloud", "storage", "rsync", "-r", src, str(dst)]
            
            print(f"\n  ğŸ“‚ {component} ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
            subprocess.run(cmd, check=True)
            print(f"  âœ“ {component} å®Œäº†")
            
    def run(self, subset: Optional[List[str]] = None):
        """ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å‡¦ç†ã‚’å®Ÿè¡Œ"""
        print("=" * 60)
        print("Nutrition5k ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ€ãƒ¼")
        print("=" * 60)
        
        # gcloud CLI ãƒã‚§ãƒƒã‚¯
        if not self.check_gcloud_installed():
            print("\nâš ï¸  gcloud CLI ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„:")
            print("  brew install --cask gcloud-cli")
            print("  ã¾ãŸã¯ https://cloud.google.com/sdk/docs/install")
            return False
            
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæº–å‚™
        self.setup_output_directory()
        
        # ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ãƒã‚§ãƒƒã‚¯
        self.check_disk_space()
        
        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Ÿè¡Œ
        start_time = time.time()
        
        if subset:
            # éƒ¨åˆ†ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            self.download_subset(subset)
            success = True
        elif self.use_tar:
            # tar.gz ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            success = self.download_tar_gz()
        else:
            # rsync ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆæ¨å¥¨ï¼‰
            success = self.download_with_rsync()
            
        elapsed_time = time.time() - start_time
        
        if success:
            print(f"\nâœ… å®Œäº†ï¼ï¼ˆæ‰€è¦æ™‚é–“: {elapsed_time/60:.1f} åˆ†ï¼‰")
            self.verify_dataset()
        else:
            print(f"\nâŒ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ")
            
        return success


def main():
    parser = argparse.ArgumentParser(
        description="Nutrition5k ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  # ãƒ•ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆæ¨å¥¨ï¼‰
  python download_nutrition5k.py
  
  # tar.gz ç‰ˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
  python download_nutrition5k.py --use-tar
  
  # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ã¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
  python download_nutrition5k.py --subset metadata
  
  # è¤‡æ•°ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
  python download_nutrition5k.py --subset metadata overhead splits
        """
    )
    
    parser.add_argument(
        "-o", "--output-dir",
        default="nutrition5k_dataset",
        help="å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: nutrition5k_datasetï¼‰"
    )
    
    parser.add_argument(
        "--use-tar",
        action="store_true",
        help="tar.gz ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆ181.4GBï¼‰"
    )
    
    parser.add_argument(
        "--subset",
        nargs="+",
        choices=["metadata", "overhead", "side_angles", "splits"],
        help="ç‰¹å®šã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®ã¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"
    )
    
    args = parser.parse_args()
    
    downloader = Nutrition5kDownloader(
        output_dir=args.output_dir,
        use_tar=args.use_tar
    )
    
    success = downloader.run(subset=args.subset)
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()