#!/usr/bin/env python3
"""
UNIMIB2016ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å…¨ç”»åƒã®EXIFæƒ…å ±ã‚’è©³ç´°åˆ†æ
"""
import os
import json
from pathlib import Path
from PIL import Image
from PIL.ExifTags import TAGS
from collections import defaultdict
import csv

def get_exif_data(image_path):
    """ç”»åƒã‹ã‚‰EXIFæƒ…å ±ã‚’å–å¾—"""
    try:
        image = Image.open(image_path)
        exifdata = image.getexif()
        
        if not exifdata:
            return None
        
        # EXIFæƒ…å ±ã‚’èª­ã¿ã‚„ã™ã„å½¢å¼ã«å¤‰æ›
        exif_dict = {}
        for tag_id, value in exifdata.items():
            tag = TAGS.get(tag_id, tag_id)
            exif_dict[tag] = value
            
        return exif_dict
    except Exception as e:
        return None

def analyze_all_images(data_dir):
    """å…¨ç”»åƒã®EXIFæƒ…å ±ã‚’åˆ†æ"""
    data_path = Path(data_dir)
    
    # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
    image_files = list(data_path.rglob('*.jpg')) + list(data_path.rglob('*.JPG'))
    
    print(f"ğŸ“ åˆ†æå¯¾è±¡: {data_dir}")
    print(f"ğŸ–¼ï¸ ç·ç”»åƒæ•°: {len(image_files)}")
    print("=" * 60)
    
    # çµ±è¨ˆæƒ…å ±
    stats = {
        'total_images': len(image_files),
        'images_with_exif': 0,
        'exif_tags_count': defaultdict(int),
        'orientation_distribution': defaultdict(int),
        'sample_images': []
    }
    
    # å…¨ç”»åƒã‚’åˆ†æ
    for img_path in image_files:
        exif_data = get_exif_data(img_path)
        
        if exif_data:
            stats['images_with_exif'] += 1
            
            # å„ã‚¿ã‚°ã®å‡ºç¾å›æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
            for tag in exif_data:
                stats['exif_tags_count'][tag] += 1
            
            # Orientationã®åˆ†å¸ƒ
            if 'Orientation' in exif_data:
                stats['orientation_distribution'][exif_data['Orientation']] += 1
            
            # ã‚µãƒ³ãƒ—ãƒ«ã‚’ä¿å­˜ï¼ˆæœ€åˆã®5æšï¼‰
            if len(stats['sample_images']) < 5:
                stats['sample_images'].append({
                    'path': str(img_path.relative_to(data_path)),
                    'exif': {k: str(v)[:100] for k, v in exif_data.items()}
                })
    
    # çµæœã®è¡¨ç¤º
    print("\nğŸ“Š åˆ†æçµæœã‚µãƒãƒªãƒ¼")
    print("=" * 60)
    print(f"ç·ç”»åƒæ•°: {stats['total_images']}")
    print(f"EXIFæƒ…å ±ã‚ã‚Š: {stats['images_with_exif']} ({stats['images_with_exif']/stats['total_images']*100:.2f}%)")
    
    print("\nğŸ“· EXIFã‚¿ã‚°ã®å‡ºç¾é »åº¦ï¼ˆä¸Šä½10ï¼‰:")
    sorted_tags = sorted(stats['exif_tags_count'].items(), key=lambda x: x[1], reverse=True)[:10]
    for tag, count in sorted_tags:
        percentage = count / stats['total_images'] * 100
        print(f"  {str(tag):25s}: {count:4d} ({percentage:6.2f}%)")
    
    print("\nğŸ”„ Orientationï¼ˆç”»åƒå‘ãï¼‰ã®åˆ†å¸ƒ:")
    orientation_names = {
        1: "é€šå¸¸",
        3: "180åº¦å›è»¢",
        6: "90åº¦æ™‚è¨ˆå›ã‚Š",
        8: "90åº¦åæ™‚è¨ˆå›ã‚Š"
    }
    for orientation, count in stats['orientation_distribution'].items():
        name = orientation_names.get(orientation, f"Unknown({orientation})")
        percentage = count / stats['total_images'] * 100
        print(f"  {name:20s}: {count:4d} ({percentage:6.2f}%)")
    
    # ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã®è©³ç´°
    if stats['sample_images']:
        print("\nğŸ“ ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã®EXIFè©³ç´°ï¼ˆæœ€åˆã®3æšï¼‰:")
        for i, sample in enumerate(stats['sample_images'][:3], 1):
            print(f"\n  ç”»åƒ {i}: {sample['path']}")
            for tag, value in sample['exif'].items():
                print(f"    {str(tag):20s}: {value}")
    
    # JSONãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜
    report_path = Path(data_dir).parent / "exif_analysis_report.json"
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(stats, f, indent=2, ensure_ascii=False, default=str)
    print(f"\nğŸ’¾ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {report_path}")
    
    # CSVãƒ¬ãƒãƒ¼ãƒˆã‚‚ä½œæˆ
    csv_path = Path(data_dir).parent / "exif_summary.csv"
    with open(csv_path, 'w', newline='', encoding='utf-8') as csvfile:
        writer = csv.writer(csvfile)
        writer.writerow(['ãƒ¡ãƒˆãƒªãƒƒã‚¯', 'å€¤', 'ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸'])
        writer.writerow(['ç·ç”»åƒæ•°', stats['total_images'], '100.00%'])
        writer.writerow(['EXIFæƒ…å ±ã‚ã‚Š', stats['images_with_exif'], 
                        f"{stats['images_with_exif']/stats['total_images']*100:.2f}%"])
        writer.writerow([])
        writer.writerow(['EXIFã‚¿ã‚°', 'å‡ºç¾å›æ•°', 'ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸'])
        for tag, count in sorted_tags:
            writer.writerow([tag, count, f"{count/stats['total_images']*100:.2f}%"])
    print(f"ğŸ’¾ CSV ã‚µãƒãƒªãƒ¼ä¿å­˜: {csv_path}")
    
    return stats

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("=" * 60)
    print("UNIMIB2016 EXIFè©³ç´°åˆ†æ")
    print("=" * 60)
    
    # è§£å‡ã—ãŸãƒ‡ãƒ¼ã‚¿ã®ãƒ‘ã‚¹
    data_dir = "data/unimib2016/pre8/pre8"
    
    if not Path(data_dir).exists():
        print(f"âŒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: {data_dir}")
        return
    
    stats = analyze_all_images(data_dir)
    
    # çµè«–
    print("\n" + "=" * 60)
    print("ğŸ” çµè«–:")
    if stats['images_with_exif'] / stats['total_images'] < 0.1:
        print("âŒ ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã¯EXIFæƒ…å ±ãŒã»ã¨ã‚“ã©å«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        print("   Kaggleç‰ˆã¯EXIFæƒ…å ±ãŒå‰Šé™¤ã•ã‚ŒãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
        print("\nğŸ’¡ æ¨å¥¨äº‹é …:")
        print("   1. ResearchGateã‹ã‚‰ç›´æ¥ã‚ªãƒªã‚¸ãƒŠãƒ«ç‰ˆã‚’å…¥æ‰‹")
        print("   2. è«–æ–‡è‘—è€…ã«ç›´æ¥é€£çµ¡ã—ã¦ã‚ªãƒªã‚¸ãƒŠãƒ«ç”»åƒã‚’è¦æ±‚")
        print("   3. ä»–ã®EXIFä¿æŒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆECUSTFDç­‰ï¼‰ã‚’æ¤œè¨")
    else:
        print("âœ… EXIFæƒ…å ±ãŒéƒ¨åˆ†çš„ã«ä¿æŒã•ã‚Œã¦ã„ã¾ã™ã€‚")
        if 'Orientation' in stats['exif_tags_count']:
            print("   - Orientationæƒ…å ±ã¯åˆ©ç”¨å¯èƒ½")
        if any(tag in stats['exif_tags_count'] for tag in ['FocalLength', 'Make', 'Model']):
            print("   - ã‚«ãƒ¡ãƒ©æƒ…å ±ã‚‚ä¸€éƒ¨åˆ©ç”¨å¯èƒ½")

if __name__ == "__main__":
    main()