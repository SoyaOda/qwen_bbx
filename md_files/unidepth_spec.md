ã€ŒQwenã®BBox â†’ SAM2.1ã®ãƒã‚¹ã‚¯ã€ã¾ã§å‡ºæ¥ã¦ã„ã‚‹ç¾çŠ¶ã‚’å‰æã«ã€UniDepth v2 ã§ â€œæ·±åº¦ãƒ»å†…å‚ãƒ»ä¿¡é ¼åº¦â€ ã‚’æ¨å®š â†’ çš¿/å“é¢å¹³é¢ã‚’RANSACã§æ¨å®š â†’ é«˜ã•ãƒãƒƒãƒ— â†’ ãƒã‚¹ã‚¯ã”ã¨ã®ä½“ç©ç©åˆ†ã¾ã§ã‚’å®Œå…¨ã«ãƒ†ã‚¹ãƒˆã§ãã‚‹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®å®Ÿè£…è¨ˆç”»ã¨æ›–æ˜§æ€§ã®ãªã„ã‚³ãƒ¼ãƒ‰ä¸€å¼ã‚’æç¤ºã—ã¾ã™ã€‚
UniDepth v2 ã¯å…¬å¼å®Ÿè£…ã§ Hugging Face ã‹ã‚‰ from_pretrained ã§ãƒ­ãƒ¼ãƒ‰ã—ã€model.infer(rgb) ã‹ã‚‰ **depth / points / intrinsicsï¼ˆV2ã¯confidenceã‚‚ï¼‰**ãŒå¾—ã‚‰ã‚Œã¾ã™ï¼ˆREADMEã®ä½¿ç”¨ä¾‹ï¼‰
GitHub
ã€‚ãƒ¢ãƒ‡ãƒ«ã¯ lpiccinelli/unidepth-v2-vitl14 ç­‰ãŒæä¾›ã•ã‚Œã¦ã„ã¾ã™ï¼ˆModel Zooï¼‰
GitHub
ã€‚

0) ç›®çš„ï¼ˆä»Šå›ãƒ†ã‚¹ãƒˆã§ã‚«ãƒãƒ¼ã™ã‚‹ã‚¿ã‚¹ã‚¯ï¼‰

UniDepth v2 ã«ã‚ˆã‚‹ ãƒ¡ãƒˆãƒªãƒƒã‚¯æ·±åº¦ï¼ˆmï¼‰ãƒ»å†…å‚Kãƒ»ä¿¡é ¼åº¦ãƒãƒƒãƒ—ã®æ¨å®š

RANSACå¹³é¢å½“ã¦ã¯ã‚ï¼ˆçš¿/å“é¢ï¼‰â†’ ç›¸å¯¾é«˜ã•ãƒãƒƒãƒ— h(x,y)ï¼ˆçš¿é¢=0ï¼‰

**SAM2.1ã®å„ãƒã‚¹ã‚¯ï¼ˆb+ / large åˆ‡æ›¿å¯ï¼‰**ã«å¯¾ã—ã¦

ä½“ç© 
ğ‘‰
â‰ˆ
âˆ‘
â„
(
ğ‘¥
,
ğ‘¦
)
â‹…
ğ‘
pix
(
ğ‘¥
,
ğ‘¦
)
Vâ‰ˆâˆ‘h(x,y)â‹…a
pix
	â€‹

(x,y) ã‚’ä¿¡é ¼åº¦ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚ã‚Š/ãªã—ã§ç®—å‡º

å¯è¦–åŒ–ï¼ˆæ·±åº¦ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ãƒ»é«˜ã•ãƒãƒƒãƒ—é‡ç•³ãƒ»3åˆ†å‰²ãƒ‘ãƒãƒ«ï¼‰

JSONå‡ºåŠ›ï¼ˆç”»åƒã”ã¨ï¼‰ï¼šå†…å‚ãƒ»å¹³é¢æ–¹ç¨‹å¼ãƒ»å„IDã®é¢ç©/ä½“ç©ï¼ˆb+ã¨largeã‚’åˆ¥æ¬„ã§ï¼‰ã‚’ä¿å­˜

ä»»æ„ï¼šPLYç‚¹ç¾¤å‡ºåŠ›ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰

æ³¨ï¼šUniDepth v2ã® API ä»•æ§˜ï¼ˆfrom_pretrained, infer, è¿”ã‚Šå€¤ depth/points/intrinsicsã€V2ã®confidenceã‚„ONNXå¯¾å¿œï¼‰ã¯å…¬å¼READMEè¨˜è¼‰ã«æº–æ‹ ã—ã¾ã™ã€‚
GitHub

1) ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹æˆï¼ˆæ—¢å­˜ãƒªãƒã«è¿½åŠ ï¼‰
qwen-vl-bbox-demo/
â”œâ”€ README.md
â”œâ”€ requirements.txt              # æ—¢å­˜ï¼‹è¿½è¨˜
â”œâ”€ config.yaml                   # æ—¢å­˜ï¼‹è¿½è¨˜
â”œâ”€ src/
â”‚  â”œâ”€ unidepth_runner.py         # â˜… UniDepth v2 æ¨è«–ï¼ˆdepth/K/conf/pointsï¼‰
â”‚  â”œâ”€ plane_fit.py               # â˜… çš¿/å“é¢ã®RANSACå¹³é¢å½“ã¦ã¯ã‚
â”‚  â”œâ”€ volume_estimator.py        # â˜… ä½“ç©ç©åˆ†ï¼ˆä¿¡é ¼åº¦ã®æœ‰ç„¡ã§2ç¨®é¡ï¼‰
â”‚  â”œâ”€ vis_depth.py               # â˜… æ·±åº¦ãƒ»é«˜ã•ã®å¯è¦–åŒ–
â”‚  â”œâ”€ run_unidepth.py            # â˜… ãƒ¡ã‚¤ãƒ³ï¼šä¸€æ‹¬ã§å‡¦ç†ãƒ»ä¿å­˜
â”‚  â””â”€ ï¼ˆæ—¢å­˜: qwen_client, run_infer, run_sam2 ãªã©ã¯ãã®ã¾ã¾ï¼‰
â””â”€ outputs/
   â””â”€ unidepth/
      â”œâ”€ depth/      # 16bit PNG / npy
      â”œâ”€ conf/       # 8bit/float confidence
      â”œâ”€ intrinsics/ # Kã‚’npyã§
      â”œâ”€ height/     # ç›¸å¯¾é«˜ã•ãƒãƒƒãƒ—
      â”œâ”€ viz/        # vizãƒ‘ãƒãƒ«ï¼ˆåŸ/æ·±åº¦/é«˜ã•ã€b+ã¨largeã®é•ã„åˆ†ã‹ã‚‹æç”»ï¼‰
      â””â”€ json/       # 1ç”»åƒã«1JSONï¼ˆä½“ç©ãƒ»é¢ç©ãªã©ï¼‰

2) ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
2.1 ä¾å­˜ï¼ˆrequirements.txt è¿½è¨˜ï¼‰
# UniDepth v2 ã¯å…¬å¼ãƒªãƒã‹ã‚‰ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆä¸‹è¨˜æ‰‹é †ï¼‰â€»pipã«ç›´æ¥æŒ‡å®šã—ãªã„
torch>=2.1.0
opencv-python>=4.9.0.80
numpy>=1.26.4
Pillow>=10.3.0
tqdm>=4.66.4

2.2 UniDepth v2 ã®å°å…¥ï¼ˆå…¬å¼æ‰‹é †ã«æº–æ‹ ï¼‰
git clone https://github.com/lpiccinelli-eth/UniDepth.git
cd UniDepth
# CUDA11.8ãƒ›ã‚¤ãƒ¼ãƒ«ã®ä¾‹ï¼ˆREADMEæº–æ‹ ï¼‰
pip install -e . --extra-index-url https://download.pytorch.org/whl/cu118


READMEã« from unidepth.models import UniDepthV1/UniDepthV2ã€model = UniDepthV2.from_pretrained("lpiccinelli/unidepth-v2-vitl14")ã€predictions = model.infer(rgb) ãªã©æ˜è¨˜ã€‚V2ã¯Confidenceå‡ºåŠ›ãƒ»ONNXå¯¾å¿œãªã©ã‚’è¿½åŠ ã€‚
GitHub

2.3 config.yaml è¿½è¨˜
unidepth:
  model_repo: "lpiccinelli/unidepth-v2-vitl14"  # V2 ViT-L
  device: "cuda"                                # or "cpu"
  save_npy: true
  save_png: true

plane:
  ring_margin_px: 40         # é£Ÿå“ãƒã‚¹ã‚¯ã®å¤–å´ãƒªãƒ³ã‚°å¹…ï¼ˆå€™è£œç‚¹æŠ½å‡ºï¼‰
  ransac_threshold_m: 0.006  # å¹³é¢è·é›¢ã®é–¾å€¤[m]ï¼ˆç´„6mmï¼‰
  ransac_max_iters: 2000
  min_support_px: 2000       # RANSACã®æœ€å°æœ‰åŠ¹ç‚¹æ•°

volume:
  use_confidence_weight: false   # trueã«ã™ã‚‹ã¨ conf ã‚’é‡ã¿ä»˜ã‘ã«ä½¿ç”¨
  area_formula: "z2_over_fx_fy"  # a_pix(z) = (z^2)/(fx*fy)
  clip_negative_height: true

paths:
  sam2_json_dir: "outputs/sam2/json"  # æ—¢å­˜ã®SAM2ã‚µãƒãƒª
  sam2_mask_dir: "outputs/sam2/masks" # æ—¢å­˜ã®ãƒã‚¹ã‚¯PNG
  qwen_json_dir: "outputs/json"       # æ—¢å­˜ã®Qwenå‡ºåŠ›ï¼ˆãƒ©ãƒ™ãƒ«ï¼‰
  input_dir: "/path/to/images"        # å…ƒç”»åƒ
  out_root: "outputs/unidepth"

mask_source: "large"   # "bplus" or "large" ã®ã©ã¡ã‚‰ã§ä½“ç©ç®—å‡ºã™ã‚‹ã‹

3) ã‚³ãƒ¼ãƒ‰å®Ÿè£…
3.1 src/unidepth_runner.pyï¼ˆUniDepth v2 æ¨è«–ï¼‰
# -*- coding: utf-8 -*-
import numpy as np
import torch
from PIL import Image
from typing import Dict, Any, Optional
from unidepth.models import UniDepthV2  # READMEã®ä½¿ç”¨ä¾‹ã«æº–æ‹  :contentReference[oaicite:4]{index=4}

class UniDepthEngine:
    def __init__(self, model_repo: str, device: str = "cuda"):
        self.device = torch.device(device if (device == "cuda" and torch.cuda.is_available()) else "cpu")
        self.model = UniDepthV2.from_pretrained(model_repo)  # HFã‹ã‚‰ãƒ­ãƒ¼ãƒ‰ï¼ˆREADMEã®Model Zooï¼‰ :contentReference[oaicite:5]{index=5}
        self.model = self.model.to(self.device)

    def infer_image(self, image_path: str) -> Dict[str, Any]:
        """RGBç”»åƒ1æšã‹ã‚‰ depth[m], intrinsics(3x3), points(3,H,W), confidence(H,W?) ã‚’è¿”ã™ã€‚"""
        rgb = torch.from_numpy(np.array(Image.open(image_path).convert("RGB"))).permute(2, 0, 1)  # C,H,W
        rgb = rgb.to(self.device)
        with torch.inference_mode():
            pred = self.model.infer(rgb)  # READMEè¨˜è¼‰ã®API :contentReference[oaicite:6]{index=6}

        # depth
        depth_t = pred.get("depth")          # (H,W) torch.Tensor
        depth = depth_t.detach().to("cpu").float().numpy()

        # intrinsics
        K_t = pred.get("intrinsics")         # (3,3)
        K = K_t.detach().to("cpu").float().numpy()

        # pointsï¼ˆã‚ã‚Œã°ä½¿ã†ã€‚ç„¡ã‘ã‚Œã°K, depthã‹ã‚‰è¨ˆç®—ï¼‰
        pts_t = pred.get("points", None)     # (3,H,W) æœŸå¾…
        if pts_t is not None:
            points = pts_t.detach().to("cpu").float().numpy()  # (3,H,W)
        else:
            points = None

        # confidenceï¼ˆV2ã§è¿½åŠ ã€‚ã‚­ãƒ¼åã¯ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«ã‚ˆã‚Šå¤‰ã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚äºŒé‡å–ã‚Šï¼‰
        conf_t = pred.get("confidence", pred.get("confidence_map", None))
        conf = None if conf_t is None else conf_t.detach().to("cpu").float().numpy()

        return {"depth": depth, "intrinsics": K, "points": points, "confidence": conf}

3.2 src/plane_fit.pyï¼ˆå“é¢RANSACï¼‰
# -*- coding: utf-8 -*-
import numpy as np
import cv2
from typing import Tuple

def build_support_ring(food_union_mask: np.ndarray, margin_px: int) -> np.ndarray:
    """é£Ÿå“ãƒã‚¹ã‚¯ã®å¤–å´ãƒªãƒ³ã‚°é ˜åŸŸï¼ˆçš¿ã‚„å“é¢å€™è£œï¼‰ã‚’ä½œæˆã€‚"""
    k = (2*margin_px + 1)
    kernel = np.ones((k, k), np.uint8)
    dil = cv2.dilate(food_union_mask.astype(np.uint8), kernel, iterations=1).astype(bool)
    ring = np.logical_and(dil, np.logical_not(food_union_mask))
    return ring

def fit_plane_ransac(points_xyz: np.ndarray, cand_mask: np.ndarray,
                     dist_th: float = 0.006, max_iters: int = 2000,
                     min_support: int = 2000, rng_seed: int = 3) -> Tuple[np.ndarray, float]:
    """
    points_xyz: (3,H,W) ã®ç‚¹ç¾¤ï¼ˆã‚«ãƒ¡ãƒ©åº§æ¨™, mï¼‰
    cand_mask : (H,W) ã®boolï¼ˆRANSACå€™è£œç‚¹ï¼‰
    dist_th   : ç‚¹â†’å¹³é¢è·é›¢[m]ã®é–¾å€¤
    æˆ»ã‚Šå€¤: (n,d) ãŸã ã— nã¯å˜ä½æ³•ç·š(3,), å¹³é¢ã¯ nÂ·X + d = 0ï¼ˆd<0æƒ³å®šï¼‰/ ã‚¤ãƒ³ãƒ©ã‚¤ã‚¢æ•°
    """
    H, W = cand_mask.shape
    ys, xs = np.where(cand_mask)
    if ys.size < min_support:
        raise RuntimeError(f"å¹³é¢å€™è£œç‚¹ãŒä¸è¶³: {ys.size} < {min_support}")

    # å€™è£œç‚¹ã®XYZã‚’æŠ½å‡º
    X = points_xyz[0, ys, xs]
    Y = points_xyz[1, ys, xs]
    Z = points_xyz[2, ys, xs]
    P = np.stack([X, Y, Z], axis=1)

    rs = np.random.RandomState(rng_seed)
    best_inliers = -1
    best_n, best_d = None, None

    for _ in range(max_iters):
        idx = rs.choice(P.shape[0], size=3, replace=False)
        p1, p2, p3 = P[idx]
        v1, v2 = p2 - p1, p3 - p1
        n = np.cross(v1, v2)
        n_norm = np.linalg.norm(n)
        if n_norm < 1e-8:
            continue
        n = n / n_norm
        d = -np.dot(n, p1)

        # ç‚¹â†’å¹³é¢è·é›¢
        dist = np.abs(P @ n + d)
        inliers = (dist < dist_th)
        n_in = int(inliers.sum())
        if n_in > best_inliers:
            # æœ€å°äºŒä¹—ã§ãƒªãƒ•ã‚¡ã‚¤ãƒ³
            Q = P[inliers]
            # min ||QÂ·n + d|| -> SVDã§ n ã‚’æ±‚ã‚ã€d ã‚’å†è¨ˆç®—
            Q1 = np.concatenate([Q, np.ones((Q.shape[0],1))], axis=1)
            # ä¿‚æ•° [n; d] ã¯æœ€å°ç‰¹ç•°å€¤ã®ç‰¹ç•°ãƒ™ã‚¯ãƒˆãƒ«
            _, _, vh = np.linalg.svd(Q1, full_matrices=False)
            coeff = vh[-1, :]
            n_ref = coeff[:3]
            n_ref /= np.linalg.norm(n_ref) + 1e-9
            d_ref = coeff[3]
            # ç¬¦å·åˆã‚ã›ï¼ˆ+Zæ–¹å‘ãŒä¸Šã«ãªã‚‹ã‚ˆã†ã«ï¼‰
            if n_ref[2] < 0:
                n_ref = -n_ref; d_ref = -d_ref
            best_n, best_d, best_inliers = n_ref, d_ref, n_in

    if best_n is None:
        raise RuntimeError("RANSACå¹³é¢æ¨å®šã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
    return (best_n, float(best_d)), float(best_inliers)

3.3 src/volume_estimator.pyï¼ˆä½“ç©ç©åˆ†ï¼‰
# -*- coding: utf-8 -*-
import numpy as np
from typing import Dict, Any

def ensure_points(depth: np.ndarray, K: np.ndarray) -> np.ndarray:
    """depth[m] ã¨å†…å‚Kã‹ã‚‰ (3,H,W) ã®ç‚¹ç¾¤ã‚’ä½œã‚‹ã€‚"""
    H, W = depth.shape
    fx, fy = K[0,0], K[1,1]
    cx, cy = K[0,2], K[1,2]
    us = np.arange(W); vs = np.arange(H)
    uu, vv = np.meshgrid(us, vs)
    Z = depth
    X = (uu - cx) / fx * Z
    Y = (vv - cy) / fy * Z
    return np.stack([X, Y, Z], axis=0)

def height_map_from_plane(points_xyz: np.ndarray, plane_n: np.ndarray, plane_d: float,
                          clip_negative: bool = True) -> np.ndarray:
    """nÂ·X + d ã®ç¬¦å·ã‚’é«˜ã•ã¨è§£é‡ˆï¼ˆçš¿é¢=0, ä¸ŠãŒæ­£ï¼‰ã€‚"""
    X = points_xyz[0]; Y = points_xyz[1]; Z = points_xyz[2]
    h = plane_n[0]*X + plane_n[1]*Y + plane_n[2]*Z + plane_d
    if clip_negative:
        h = np.maximum(h, 0.0)
    return h

def pixel_area_map(depth: np.ndarray, K: np.ndarray) -> np.ndarray:
    """a_pix(z) â‰ˆ (z^2)/(fx*fy)ï¼ˆå°é¢ç©è¿‘ä¼¼ï¼‰ã€‚"""
    fx, fy = K[0,0], K[1,1]
    return (depth**2) / (fx * fy + 1e-12)

def integrate_volume(height: np.ndarray, a_pix: np.ndarray,
                     mask_bool: np.ndarray, conf: np.ndarray = None,
                     use_conf_weight: bool = False) -> Dict[str, Any]:
    """maskå†…ã§ V ã‚’ç©åˆ†ã€‚confé‡ã¿ã¯ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆæ¯”è¼ƒã®ãŸã‚ä¸¡æ–¹å‡ºã™ã®ãŒæ¨å¥¨ï¼‰ã€‚"""
    m = mask_bool.astype(bool)
    if not np.any(m):
        return {"pixels": 0, "volume_mL": 0.0}
    if use_conf_weight and (conf is not None):
        w = conf
        V = float(np.sum(height[m] * a_pix[m] * np.clip(w[m], 0.0, 1.0)))
    else:
        V = float(np.sum(height[m] * a_pix[m]))
    # m^3 â†’ mL(=1e6 * m^3)
    return {"pixels": int(m.sum()), "volume_mL": V * 1e6}

3.4 src/vis_depth.pyï¼ˆå¯è¦–åŒ–ï¼‰
# -*- coding: utf-8 -*-
import numpy as np
import cv2

def colorize_depth(depth: np.ndarray, clip_q=(0.02, 0.98)) -> np.ndarray:
    d = depth.copy()
    lo, hi = np.quantile(d[np.isfinite(d)], clip_q)
    d = np.clip((d - lo) / max(1e-9, (hi - lo)), 0, 1)
    d8 = (d * 255).astype(np.uint8)
    return cv2.applyColorMap(d8, cv2.COLORMAP_TURBO)

def colorize_height(height: np.ndarray, max_h_m: float = 0.05) -> np.ndarray:
    """0ã€œmax_h_m ã‚’ 0ã€œ255 ã«æ­£è¦åŒ–ã—ã¦ã‚«ãƒ©ãƒãƒƒãƒ—ã€‚"""
    h = np.clip(height / max_h_m, 0, 1)
    h8 = (h * 255).astype(np.uint8)
    return cv2.applyColorMap(h8, cv2.COLORMAP_MAGMA)

3.5 src/run_unidepth.pyï¼ˆãƒ¡ã‚¤ãƒ³ï¼šæ·±åº¦â†’å¹³é¢â†’ä½“ç©ï¼‰
# -*- coding: utf-8 -*-
import os, json, glob
import numpy as np
import cv2
import yaml
from PIL import Image
from tqdm import tqdm

from src.unidepth_runner import UniDepthEngine
from src.plane_fit import build_support_ring, fit_plane_ransac
from src.volume_estimator import ensure_points, height_map_from_plane, pixel_area_map, integrate_volume
from src.vis_depth import colorize_depth, colorize_height
from src.visualize import ensure_dir

def load_sam2_summary(json_path: str):
    with open(json_path, "r", encoding="utf-8") as f:
        return json.load(f)

def load_binary_mask(path: str) -> np.ndarray:
    m = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
    if m is None:
        raise FileNotFoundError(path)
    return (m > 127)

def find_mask_files(mask_dir: str, stem: str, det_idx: int, label: str, source: str):
    # run_sam2.py ã®å‘½åè¦å‰‡: <stem>_det##_<label>_<bplus|large>.png
    safe_lab = "".join([c if c.isalnum() else "_" for c in label])[:40]
    return os.path.join(mask_dir, f"{stem}_det{det_idx:02d}_{safe_lab}_{source}.png")

def main():
    with open("config.yaml", "r", encoding="utf-8") as f:
        cfg = yaml.safe_load(f)

    uni_cfg   = cfg["unidepth"]
    plane_cfg = cfg["plane"]
    vol_cfg   = cfg["volume"]
    paths     = cfg["paths"]
    src_name  = cfg.get("mask_source", "large")

    out_root = paths["out_root"]
    ddir = os.path.join(out_root, "depth")
    cdir = os.path.join(out_root, "conf")
    kdir = os.path.join(out_root, "intrinsics")
    hdir = os.path.join(out_root, "height")
    vdir = os.path.join(out_root, "viz")
    jdir = os.path.join(out_root, "json")
    for d in (ddir, cdir, kdir, hdir, vdir, jdir): ensure_dir(d)

    # UniDepthãƒ¢ãƒ‡ãƒ«
    engine = UniDepthEngine(uni_cfg["model_repo"], device=uni_cfg.get("device", "cuda"))

    # å…¥åŠ›ç”»åƒ
    img_dir    = paths["input_dir"]
    sam2_dir   = paths["sam2_json_dir"]
    mask_dir   = paths["sam2_mask_dir"]
    stems = []
    for p in glob.glob(os.path.join(img_dir, "*")):
        if os.path.splitext(p)[1].lower() in (".jpg", ".jpeg", ".png", ".bmp", ".webp"):
            stems.append(os.path.splitext(os.path.basename(p))[0])
    stems.sort()

    for stem in tqdm(stems, desc="UniDepthV2 â†’ å¹³é¢ â†’ ä½“ç©"):
        img_path  = os.path.join(img_dir, f"{stem}.jpg")
        if not os.path.exists(img_path):
            # ä»–æ‹¡å¼µå­å¯¾å¿œ
            alt = [".png", ".jpeg", ".bmp", ".webp"]
            found = False
            for ext in alt:
                p = os.path.join(img_dir, f"{stem}{ext}")
                if os.path.exists(p): img_path=p; found=True; break
            if not found: continue

        # 1) UniDepth æ¨è«–
        pred = engine.infer_image(img_path)
        depth, K, points, conf = pred["depth"], pred["intrinsics"], pred["points"], pred["confidence"]
        H, W = depth.shape
        if points is None:
            points = ensure_points(depth, K)

        # ä¿å­˜
        if uni_cfg.get("save_npy", True):
            np.save(os.path.join(ddir, f"{stem}.npy"), depth)
            np.save(os.path.join(kdir, f"{stem}.K.npy"), K)
            if conf is not None:
                np.save(os.path.join(cdir, f"{stem}.conf.npy"), conf)
        if uni_cfg.get("save_png", True):
            cv2.imwrite(os.path.join(ddir, f"{stem}.png"), (np.clip(depth, 0, np.nanpercentile(depth, 99)) * 1000).astype(np.uint16))
            if conf is not None:
                c8 = (np.clip(conf, 0, 1) * 255).astype(np.uint8)
                cv2.imwrite(os.path.join(cdir, f"{stem}.png"), c8)

        # 2) SAM2ã®æ¤œå‡ºã‚’ãƒ­ãƒ¼ãƒ‰
        sam2_json_path = os.path.join(sam2_dir, f"{stem}.sam2.json")
        if not os.path.exists(sam2_json_path):
            # Qwen/SAMãªã—ç”»åƒã¯ã‚¹ã‚­ãƒƒãƒ—
            continue
        summ = load_sam2_summary(sam2_json_path)
        dets = summ.get("detections", [])
        labels = [d["label_ja"] for d in dets]

        # é£Ÿå“Unionãƒã‚¹ã‚¯
        union = np.zeros((H, W), dtype=bool)
        masks = []
        for i, lab in enumerate(labels):
            mpath = find_mask_files(mask_dir, stem, i, lab, "large" if src_name=="large" else "bplus")
            m = load_binary_mask(mpath)
            masks.append(m)
            union |= m

        # 3) å¹³é¢å€™è£œç‚¹ï¼ˆãƒªãƒ³ã‚°ï¼‰â†’ RANSAC
        ring = build_support_ring(union, margin_px=int(plane_cfg["ring_margin_px"]))
        try:
            (n, d), nin = fit_plane_ransac(points, ring,
                                           dist_th=float(plane_cfg["ransac_threshold_m"]),
                                           max_iters=int(plane_cfg["ransac_max_iters"]),
                                           min_support=int(plane_cfg["min_support_px"]))
        except RuntimeError:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šç”»åƒå…¨åŸŸã‹ã‚‰RANSACï¼ˆå°ç‰©ãŒå¤šã„å ´åˆãªã©ï¼‰
            full = np.logical_not(union)
            (n, d), nin = fit_plane_ransac(points, full,
                                           dist_th=float(plane_cfg["ransac_threshold_m"]),
                                           max_iters=int(plane_cfg["ransac_max_iters"]),
                                           min_support=int(plane_cfg["min_support_px"]//2))

        # 4) é«˜ã•ãƒ»é¢ç©ãƒãƒƒãƒ—
        height = height_map_from_plane(points, n, d, clip_negative=bool(vol_cfg.get("clip_negative_height", True)))
        a_pix  = pixel_area_map(depth, K)

        # 5) ä½“ç©ï¼ˆconfæœ‰/ç„¡ï¼‰
        out_items = []
        for i, lab in enumerate(labels):
            vol_plain = integrate_volume(height, a_pix, masks[i], conf=None, use_conf_weight=False)
            vol_conf  = integrate_volume(height, a_pix, masks[i], conf=conf, use_conf_weight=bool(vol_cfg["use_confidence_weight"]))
            out_items.append({
                "id": i,
                "label_ja": lab,
                "pixels": vol_plain["pixels"],
                "volume_mL_no_conf": vol_plain["volume_mL"],
                "volume_mL_conf": vol_conf["volume_mL"] if vol_cfg["use_confidence_weight"] and conf is not None else None
            })

        # 6) å¯è¦–åŒ–
        img_bgr = cv2.cvtColor(np.array(Image.open(img_path).convert("RGB")), cv2.COLOR_RGB2BGR)
        depth_cm = colorize_depth(depth)
        height_cm = colorize_height(height, max_h_m=0.05)  # 5cmä¸Šé™ã§æ­£è¦åŒ–
        panel = np.concatenate([img_bgr, depth_cm, height_cm], axis=1)
        cv2.imwrite(os.path.join(vdir, f"{stem}_panel.jpg"), panel)

        # 7) JSONä¿å­˜
        js = {
            "image": os.path.basename(img_path),
            "width": W, "height": H,
            "intrinsics": K.tolist(),
            "plane": {"n": n.tolist(), "d": float(d)},
            "mask_source": src_name,
            "detections": out_items
        }
        with open(os.path.join(jdir, f"{stem}.unidepth.json"), "w", encoding="utf-8") as f:
            json.dump(js, f, ensure_ascii=False, indent=2)

    print(f"å®Œäº†: {out_root}")

if __name__ == "__main__":
    main()

4) å®Ÿè¡Œ
# 1) æ—¢å­˜ã® Qwen â†’ SAM2.1 (b+ / large) ãŒå®Œäº†ã—ã¦ã„ã‚‹å‰æ
# 2) UniDepth v2 ã®ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆå‰è¿°ï¼‰
python -m src.run_unidepth
# å‡ºåŠ›ã¯ outputs/unidepth/ é…ä¸‹ã«ä¿å­˜


viz/xxx_panel.jpg â€¦ åŸç”»åƒï½œæ·±åº¦ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï½œé«˜ã•ãƒãƒƒãƒ—

json/xxx.unidepth.json â€¦ Kãƒ»å¹³é¢ãƒ»å„IDã®ä½“ç©ï¼ˆmLï¼‰

depth/xxx.npy|png, intrinsics/xxx.K.npy, conf/xxx.npy|png, height/xxx.npy|png

5) ã‚µãƒ‹ãƒ†ã‚£ãƒã‚§ãƒƒã‚¯ï¼ˆæœ€å°ï¼‰

(A) å¹³é¢æ¨å®šã®æœ‰åŠ¹ç‚¹æ•°ãƒ»æ®‹å·®ã‚’ç¢ºèª
fit_plane_ransac ã§ ninï¼ˆã‚¤ãƒ³ãƒ©ã‚¤ã‚¢æ•°ï¼‰ãŒé–¾å€¤ä»¥ä¸Šã«ãªã£ã¦ã„ã‚‹ã‹ã€‚
(B) é«˜ã•ã®ç¯„å›²
height ã® 99ï¼…åˆ†ä½ãŒ 1ã€œ50mm ç¨‹åº¦ã«åã¾ã‚‹ã‹ï¼ˆæ–™ç†ã®åšã¿ã®å¸¸è­˜ç¯„å›²ï¼‰ã€‚
(C) ä½“ç©ã®ã‚ªãƒ¼ãƒ€
ä¸€å“ã®ä½“ç©ãŒ 50â€“600 mL ç¨‹åº¦ã«å¤šããŒåã¾ã‚‹ã‹ï¼ˆæ±ç‰©ã¯å™¨å®¹é‡ã§ä¸Šé™ã‚’ç¢ºèªï¼‰ã€‚

6) ã‚ˆãã‚ã‚‹è³ªå•ï¼èª¿æ•´ãƒã‚¤ãƒ³ãƒˆ

confidence ã®ä½¿ã„æ–¹
V2ã¯confidenceå‡ºåŠ›ã‚’æŒã¡ã¾ã™ï¼ˆREADMEã«ã€ŒConfidence outputã€ã¨æ˜è¨˜ï¼‰
GitHub
ã€‚ãƒ†ã‚¹ãƒˆã§ã¯ æœªä½¿ç”¨ç‰ˆã¨é‡ã¿ä»˜ç‰ˆã®ä¸¡æ–¹ã‚’JSONã«å…¥ã‚Œã€æŒ™å‹•ã‚’æ¯”è¼ƒã—ã¦ãã ã•ã„ã€‚

a_pix ã®å¼
è¿‘ä¼¼ã¨ã—ã¦ 
ğ‘
pix
(
ğ‘§
)
=
(
ğ‘§
2
)
/
(
ğ‘“
ğ‘¥
â‹…
ğ‘“
ğ‘¦
)
a
pix
	â€‹

(z)=(z
2
)/(fxâ‹…fy) ã‚’æ¡ç”¨ã€‚å³å¯†ã«ã¯è¦–ç·šæ–¹å‘ã‚„é¢ã®å‚¾ãã«ä¾å­˜ã—ã¾ã™ãŒã€çš¿ä»˜è¿‘ã®ç‹­ã„ç¯„å›²ã§ã®ç©åˆ†è¿‘ä¼¼ã¨ã—ã¦ååˆ†å®Ÿç”¨ã§ã™ã€‚

ãƒªãƒ³ã‚°ã®å¤±æ•—æ™‚
é£Ÿå“ãŒç”»é¢ã„ã£ã±ã„ã®å ´åˆãªã©ãƒªãƒ³ã‚°ãŒå°ã•ã„ã¨RANSACãŒå¤±æ•—ã—ã¾ã™ã€‚ã‚³ãƒ¼ãƒ‰ã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã§å…¨åŸŸã‹ã‚‰å†æ¨å®šã—ã¾ã™ã€‚

b+ / large ã®æ¯”è¼ƒ
config.yaml ã® mask_source ã‚’åˆ‡ã‚Šæ›¿ãˆã¦åŒã˜UniDepthçµæœã«å¯¾ã—ãƒã‚¹ã‚¯å·®ã«ã‚ˆã‚‹ä½“ç©å·®ã‚’æ¤œè¨¼ã§ãã¾ã™ã€‚

ãƒ©ã‚¤ã‚»ãƒ³ã‚¹
UniDepthã¯ CC BY-NC 4.0ã€‚éå•†ç”¨ã§ã‚ã‚‹ç‚¹ã«æ³¨æ„ï¼ˆREADMEè¨˜è¼‰ï¼‰ã€‚
GitHub