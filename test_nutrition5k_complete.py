#!/usr/bin/env python3
"""
Nutrition5kãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®å®Œå…¨ãªä½“ç©äºˆæ¸¬ãƒ†ã‚¹ãƒˆ
- QwenVL-2Bã§é£Ÿå“æ¤œå‡º
- SAM2.1ã§ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
- GTæ·±åº¦ã¨Depth Anything V2ã§ã®æ¯”è¼ƒ
test_depthanything_v2.pyã‚’å‚è€ƒã«Nutrition5kç”¨ã«æœ€é©åŒ–
"""

import os
import sys
import numpy as np
import cv2
import torch
from PIL import Image
from transformers import AutoImageProcessor, AutoModelForDepthEstimation
from transformers import Qwen2VLForConditionalGeneration, AutoProcessor
# SAM2ã‚’Transformersã‹ã‚‰ä½¿ç”¨
from transformers import Sam2Model, Sam2Processor

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))
sys.path.append(os.path.join(os.path.dirname(__file__), 'nutrition5k'))

from plane_fit import estimate_plane_from_depth
from volume_estimator import height_map_from_plane, pixel_area_map, integrate_volume
from preprocess_nutrition5k import depth_raw_to_meters, get_K_matrix, process_dish


class Nutrition5kCompleteTest:
    """Nutrition5kãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®å®Œå…¨ãªä½“ç©äºˆæ¸¬ãƒ†ã‚¹ãƒˆ"""
    
    def __init__(self, root_dir="nutrition5k/nutrition5k_dataset"):
        self.root_dir = root_dir
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        
        print("ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ä¸­...")
        print("-" * 70)
        
        # 1. QwenVL-2Bãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
        print("1. QwenVL-2B-Instructã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
        self.qwen_model = Qwen2VLForConditionalGeneration.from_pretrained(
            "Qwen/Qwen2-VL-2B-Instruct",
            torch_dtype="auto",
            device_map="auto"
        )
        self.qwen_processor = AutoProcessor.from_pretrained("Qwen/Qwen2-VL-2B-Instruct")
        print("  âœ“ QwenVL-2B ãƒ­ãƒ¼ãƒ‰å®Œäº†")
        
        # 2. SAM2.1ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ï¼ˆTransformersã‹ã‚‰ï¼‰
        print("2. SAM2.1ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
        try:
            self.sam2_model = Sam2Model.from_pretrained("facebook/sam2.1-hiera-large")
            self.sam2_processor = Sam2Processor.from_pretrained("facebook/sam2.1-hiera-large")
            self.sam2_model = self.sam2_model.to(self.device)
            self.sam2_predictor = True  # ãƒ•ãƒ©ã‚°ã¨ã—ã¦ä½¿ç”¨
            print("  âœ“ SAM2.1 ãƒ­ãƒ¼ãƒ‰å®Œäº†")
        except Exception as e:
            print(f"  âš  SAM2.1ã®ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—: {e}")
            self.sam2_predictor = None
        
        # 3. Depth Anything V2ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
        print("3. Depth Anything V2ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
        self.da_processor = AutoImageProcessor.from_pretrained(
            "depth-anything/Depth-Anything-V2-Metric-Indoor-Large-hf"
        )
        self.da_model = AutoModelForDepthEstimation.from_pretrained(
            "depth-anything/Depth-Anything-V2-Metric-Indoor-Large-hf"
        ).to(self.device).eval()
        print("  âœ“ Depth Anything V2 ãƒ­ãƒ¼ãƒ‰å®Œäº†")
        
        print("-" * 70)
        print(f"ã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å®Œäº† (device: {self.device})\n")
    
    def detect_foods_qwen(self, image):
        """QwenVL-2Bã§é£Ÿå“ã‚’æ¤œå‡º"""
        
        # PIL Imageã«å¤‰æ›
        if isinstance(image, np.ndarray):
            image_pil = Image.fromarray(image)
        else:
            image_pil = image
        
        # é£Ÿå“æ¤œå‡ºç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆNutrition5kå‘ã‘ã«æœ€é©åŒ–ï¼‰
        messages = [
            {
                "role": "user",
                "content": [
                    {
                        "type": "image",
                        "image": image_pil,
                    },
                    {
                        "type": "text",
                        "text": "Identify all food items in this overhead view image. List each food with its approximate center location as percentage (x%, y%) from top-left. Format: 'food_name at (x%, y%)'. Be specific about food types."
                    },
                ],
            }
        ]
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå‡¦ç†
        text = self.qwen_processor.apply_chat_template(
            messages, tokenize=False, add_generation_prompt=True
        )
        
        image_inputs, video_inputs = process_vision_info(messages)
        inputs = self.qwen_processor(
            text=[text],
            images=image_inputs,
            videos=video_inputs,
            padding=True,
            return_tensors="pt",
        )
        inputs = inputs.to(self.device)
        
        # æ¨è«–å®Ÿè¡Œ
        with torch.no_grad():
            generated_ids = self.qwen_model.generate(**inputs, max_new_tokens=256)
            generated_ids_trimmed = [
                out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)
            ]
            output_text = self.qwen_processor.batch_decode(
                generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False
            )[0]
        
        # æ¤œå‡ºçµæœã‚’ãƒ‘ãƒ¼ã‚¹
        detections = []
        lines = output_text.strip().split('\n')
        
        for line in lines:
            if ' at (' in line and '%)' in line:
                try:
                    # "food_name at (x%, y%)" å½¢å¼ã‚’ãƒ‘ãƒ¼ã‚¹
                    parts = line.split(' at (')
                    food_name = parts[0].strip()
                    coords = parts[1].replace('%)', '').replace('%', '').split(',')
                    x_pct = float(coords[0].strip())
                    y_pct = float(coords[1].strip())
                    
                    # ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸ã‚’ãƒ”ã‚¯ã‚»ãƒ«åº§æ¨™ã«å¤‰æ›
                    h, w = image.shape[:2] if isinstance(image, np.ndarray) else image_pil.size[::-1]
                    x = int(w * x_pct / 100)
                    y = int(h * y_pct / 100)
                    
                    detections.append({
                        'label': food_name,
                        'point': [x, y]
                    })
                except:
                    continue
        
        return detections
    
    def segment_with_sam(self, image, detections):
        """SAM2.1ã§é£Ÿå“ã‚’ã‚»ã‚°ãƒ¡ãƒ³ãƒˆï¼ˆç°¡ç•¥ç‰ˆï¼‰"""
        
        # ç¾åœ¨ã¯SAM2ã‚’ä½¿ã‚ãšã€ç°¡æ˜“çš„ãªãƒã‚¹ã‚¯ã‚’ç”Ÿæˆ
        if isinstance(image, Image.Image):
            image_np = np.array(image)
        else:
            image_np = image
        
        h, w = image_np.shape[:2]
        masks = []
        labels = []
        
        for det in detections:
            # ãƒã‚¤ãƒ³ãƒˆå‘¨è¾ºã®å††å½¢ãƒã‚¹ã‚¯ã‚’ç”Ÿæˆï¼ˆæš«å®šï¼‰
            mask = np.zeros((h, w), dtype=bool)
            x, y = det['point']
            radius = min(h, w) // 6  # ç”»åƒã‚µã‚¤ã‚ºã®1/6ç¨‹åº¦
            
            yy, xx = np.meshgrid(np.arange(h), np.arange(w), indexing='ij')
            distance = np.sqrt((yy - y)**2 + (xx - x)**2)
            mask = distance < radius
            
            masks.append(mask)
            labels.append(det['label'])
        
        return masks, labels
    
    def predict_depth_anything(self, rgb_image, K_scale_factor=10.5):
        """Depth Anything V2ã§æ·±åº¦äºˆæ¸¬ï¼ˆNutrition5kç”¨ã«èª¿æ•´ï¼‰"""
        
        # PIL Imageå½¢å¼ã«å¤‰æ›
        if isinstance(rgb_image, np.ndarray):
            img_pil = Image.fromarray(rgb_image)
        else:
            img_pil = rgb_image
        
        orig_w, orig_h = img_pil.size
        
        # ãƒ¢ãƒ‡ãƒ«å…¥åŠ›ã‚’æº–å‚™
        inputs = self.da_processor(images=img_pil, return_tensors="pt")
        inputs = {k: v.to(self.device) for k, v in inputs.items()}
        
        # æ¨è«–å®Ÿè¡Œ
        with torch.no_grad():
            outputs = self.da_model(**inputs)
        
        # æ·±åº¦ãƒãƒƒãƒ—ã‚’å–å¾—
        if hasattr(outputs, 'predicted_depth'):
            pred_depth = outputs.predicted_depth
        else:
            pred_depth = outputs.logits if hasattr(outputs, 'logits') else outputs[0]
        
        # é©åˆ‡ãªå½¢çŠ¶ã«å¤‰æ›
        if len(pred_depth.shape) == 3:
            pred_depth = pred_depth.unsqueeze(1)
        elif len(pred_depth.shape) == 2:
            pred_depth = pred_depth.unsqueeze(0).unsqueeze(0)
        
        # å…ƒã®ã‚µã‚¤ã‚ºã«ãƒªã‚µã‚¤ã‚º
        if pred_depth.shape[-2:] != (orig_h, orig_w):
            pred_depth = torch.nn.functional.interpolate(
                pred_depth, size=(orig_h, orig_w),
                mode="bicubic", align_corners=False
            )
        
        # numpyé…åˆ—ã«å¤‰æ›
        depth_map = pred_depth[0, 0].cpu().numpy()
        
        return depth_map, K_scale_factor
    
    def calculate_volumes(self, depth_map, K, masks, labels):
        """å„ãƒã‚¹ã‚¯ã®ä½“ç©ã‚’è¨ˆç®—"""
        
        if not masks:
            return None
        
        try:
            # ãƒ†ãƒ¼ãƒ–ãƒ«å¹³é¢ã‚’æ¨å®š
            plane_normal, plane_distance, points_xyz = estimate_plane_from_depth(
                depth_map, K, masks,
                margin_px=40,
                dist_th=0.006,
                max_iters=2000
            )
            
            # é«˜ã•ãƒãƒƒãƒ—ã‚’è¨ˆç®—
            height_map = height_map_from_plane(
                points_xyz, plane_normal, plane_distance, 
                clip_negative=True
            )
            
            # ãƒ”ã‚¯ã‚»ãƒ«é¢ç©ãƒãƒƒãƒ—ã‚’è¨ˆç®—
            area_map = pixel_area_map(depth_map, K)
            
            # å„ãƒã‚¹ã‚¯ã®ä½“ç©ã‚’è¨ˆç®—
            results = []
            total_volume = 0.0
            
            for mask, label in zip(masks, labels):
                vol_result = integrate_volume(
                    height_map, area_map, mask,
                    conf=None, use_conf_weight=False
                )
                
                volume_mL = vol_result["volume_mL"]
                height_mean = vol_result["height_mean_mm"]
                height_max = vol_result["height_max_mm"]
                
                total_volume += volume_mL
                
                results.append({
                    'label': label,
                    'volume_mL': volume_mL,
                    'height_mean_mm': height_mean,
                    'height_max_mm': height_max
                })
            
            return {
                'total_volume_mL': total_volume,
                'foods': results
            }
            
        except Exception as e:
            print(f"  ä½“ç©è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def test_single_dish(self, dish_id):
        """å˜ä¸€ã®dishã§å®Œå…¨ãªãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
        
        print(f"\n{'='*70}")
        print(f"Dish: {dish_id}")
        print(f"{'='*70}")
        
        # 1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        data = process_dish(dish_id, self.root_dir, verbose=False)
        if data is None:
            print(f"ã‚¨ãƒ©ãƒ¼: {dish_id}ã®ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å¤±æ•—")
            return None
        
        rgb = data['rgb']
        gt_depth = data['depth_m']
        K = data['K']
        
        print(f"\n1. ãƒ‡ãƒ¼ã‚¿æƒ…å ±:")
        print(f"  ç”»åƒã‚µã‚¤ã‚º: {rgb.shape[1]}x{rgb.shape[0]}")
        print(f"  Kè¡Œåˆ—: fx={K[0,0]:.1f}, fy={K[1,1]:.1f}")
        
        # GTæ·±åº¦ã®çµ±è¨ˆ
        valid_gt = gt_depth[gt_depth > 0]
        if len(valid_gt) > 0:
            print(f"  GTæ·±åº¦ç¯„å›²: {valid_gt.min():.3f} - {valid_gt.max():.3f} m")
            print(f"  GTæ·±åº¦ä¸­å¤®å€¤: {np.median(valid_gt):.3f} m")
        
        # 2. QwenVLã§é£Ÿå“æ¤œå‡º
        print(f"\n2. QwenVL-2Bã§é£Ÿå“æ¤œå‡º:")
        detections = self.detect_foods_qwen(rgb)
        
        if detections:
            print(f"  æ¤œå‡ºæ•°: {len(detections)}å€‹")
            for det in detections:
                print(f"    - {det['label']} at ({det['point'][0]}, {det['point'][1]})")
        else:
            print("  é£Ÿå“ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šç”»åƒä¸­å¤®ã«ãƒ€ãƒŸãƒ¼æ¤œå‡º
            h, w = rgb.shape[:2]
            detections = [{'label': 'food', 'point': [w//2, h//2]}]
        
        # 3. SAM2.1ã§ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
        print(f"\n3. SAM2.1ã§ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³:")
        if self.sam2_predictor:
            masks, labels = self.segment_with_sam(rgb, detections)
            print(f"  ãƒã‚¹ã‚¯ç”Ÿæˆ: {len(masks)}å€‹")
            
            for i, (mask, label) in enumerate(zip(masks, labels)):
                pixels = np.sum(mask)
                pct = pixels / (mask.shape[0] * mask.shape[1]) * 100
                print(f"    - {label}: {pixels}ãƒ”ã‚¯ã‚»ãƒ« ({pct:.1f}%)")
        else:
            print("  SAM2.1ãŒåˆ©ç”¨ä¸å¯ - ç°¡æ˜“ãƒã‚¹ã‚¯ã‚’ä½¿ç”¨")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šæ·±åº¦é–¾å€¤ã§ãƒã‚¹ã‚¯ç”Ÿæˆ
            threshold = np.percentile(valid_gt, 30)
            mask = (gt_depth > 0) & (gt_depth < threshold)
            masks = [mask]
            labels = ['food']
        
        # 4. GTæ·±åº¦ã‹ã‚‰ã®ä½“ç©è¨ˆç®—
        print(f"\n4. GTæ·±åº¦ã‹ã‚‰ã®ä½“ç©è¨ˆç®—:")
        gt_volumes = self.calculate_volumes(gt_depth, K, masks, labels)
        
        if gt_volumes:
            print(f"  åˆè¨ˆä½“ç©: {gt_volumes['total_volume_mL']:.1f} mL")
            for food in gt_volumes['foods']:
                status = "âœ“" if 10 <= food['volume_mL'] <= 1000 else "âš "
                print(f"    {food['label']:20s}: {food['volume_mL']:7.1f} mL "
                      f"(é«˜ã•: å¹³å‡{food['height_mean_mm']:.1f}mm, æœ€å¤§{food['height_max_mm']:.1f}mm) {status}")
        
        # 5. Depth Anything V2ã§ã®äºˆæ¸¬
        print(f"\n5. Depth Anything V2ã§ã®æ·±åº¦äºˆæ¸¬:")
        pred_depth, K_scale_factor = self.predict_depth_anything(rgb)
        
        # äºˆæ¸¬æ·±åº¦ã®çµ±è¨ˆ
        valid_pred = pred_depth[pred_depth > 0]
        if len(valid_pred) > 0:
            print(f"  äºˆæ¸¬æ·±åº¦ç¯„å›²: {valid_pred.min():.3f} - {valid_pred.max():.3f} m")
            print(f"  äºˆæ¸¬æ·±åº¦ä¸­å¤®å€¤: {np.median(valid_pred):.3f} m")
        
        # ã‚¹ã‚±ãƒ¼ãƒ«èª¿æ•´
        if len(valid_gt) > 0 and len(valid_pred) > 0:
            scale_factor = np.median(valid_gt) / np.median(valid_pred)
            print(f"  æ·±åº¦ã‚¹ã‚±ãƒ¼ãƒ«èª¿æ•´: Ã—{scale_factor:.2f}")
            pred_depth_scaled = pred_depth * scale_factor
        else:
            pred_depth_scaled = pred_depth
            scale_factor = 1.0
        
        # Kè¡Œåˆ—ã®èª¿æ•´ï¼ˆUniDepth v2ã®çµŒé¨“ã‹ã‚‰ï¼‰
        K_pred = K.copy()
        K_pred[0,0] *= K_scale_factor
        K_pred[1,1] *= K_scale_factor
        print(f"  K_scale_factor: {K_scale_factor}")
        
        # 6. äºˆæ¸¬æ·±åº¦ã‹ã‚‰ã®ä½“ç©è¨ˆç®—
        print(f"\n6. äºˆæ¸¬æ·±åº¦ã‹ã‚‰ã®ä½“ç©è¨ˆç®—:")
        pred_volumes = self.calculate_volumes(pred_depth_scaled, K_pred, masks, labels)
        
        if pred_volumes:
            print(f"  åˆè¨ˆä½“ç©: {pred_volumes['total_volume_mL']:.1f} mL")
            for food in pred_volumes['foods']:
                status = "âœ“" if 10 <= food['volume_mL'] <= 1000 else "âš "
                print(f"    {food['label']:20s}: {food['volume_mL']:7.1f} mL "
                      f"(é«˜ã•: å¹³å‡{food['height_mean_mm']:.1f}mm, æœ€å¤§{food['height_max_mm']:.1f}mm) {status}")
        
        # 7. æ¯”è¼ƒè©•ä¾¡
        print(f"\n7. æ¯”è¼ƒè©•ä¾¡:")
        if gt_volumes and pred_volumes:
            gt_total = gt_volumes['total_volume_mL']
            pred_total = pred_volumes['total_volume_mL']
            
            error = abs(gt_total - pred_total)
            error_pct = (error / gt_total) * 100 if gt_total > 0 else 0
            
            print(f"  GTåˆè¨ˆä½“ç©: {gt_total:.1f} mL")
            print(f"  äºˆæ¸¬åˆè¨ˆä½“ç©: {pred_total:.1f} mL")
            print(f"  çµ¶å¯¾èª¤å·®: {error:.1f} mL")
            print(f"  ç›¸å¯¾èª¤å·®: {error_pct:.1f}%")
            
            if error_pct < 20:
                print("  â†’ âœ“ å„ªç§€ï¼ˆèª¤å·®20%ä»¥å†…ï¼‰")
            elif error_pct < 50:
                print("  â†’ â–³ è¨±å®¹ç¯„å›²ï¼ˆèª¤å·®50%ä»¥å†…ï¼‰")
            else:
                print("  â†’ âœ— è¦æ”¹å–„ï¼ˆèª¤å·®50%è¶…ï¼‰")
            
            # å€‹åˆ¥é£Ÿå“ã®æ¯”è¼ƒ
            if len(gt_volumes['foods']) == len(pred_volumes['foods']):
                print("\n  å€‹åˆ¥é£Ÿå“ã®æ¯”è¼ƒ:")
                for gt_food, pred_food in zip(gt_volumes['foods'], pred_volumes['foods']):
                    gt_vol = gt_food['volume_mL']
                    pred_vol = pred_food['volume_mL']
                    err = abs(gt_vol - pred_vol) / gt_vol * 100 if gt_vol > 0 else 0
                    print(f"    {gt_food['label']:20s}: GT={gt_vol:6.1f} mL, äºˆæ¸¬={pred_vol:6.1f} mL, èª¤å·®={err:.1f}%")
        
        return {
            'dish_id': dish_id,
            'gt_volumes': gt_volumes,
            'pred_volumes': pred_volumes,
            'detections': len(detections),
            'masks': len(masks)
        }


def process_vision_info(messages):
    """QwenVLç”¨ã®ãƒ“ã‚¸ãƒ§ãƒ³æƒ…å ±å‡¦ç†ï¼ˆãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ï¼‰"""
    image_inputs = []
    video_inputs = []
    for message in messages:
        if isinstance(message["content"], list):
            for ele in message["content"]:
                if ele.get("type") == "image":
                    image_inputs.append(ele["image"])
                elif ele.get("type") == "video":
                    video_inputs.append(ele["video"])
    return image_inputs, video_inputs


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    
    print("\n" + "="*70)
    print("Nutrition5k å®Œå…¨ä½“ç©äºˆæ¸¬ãƒ†ã‚¹ãƒˆ")
    print("ï¼ˆQwenVL + SAM2.1 + Depth Anything V2ï¼‰")
    print("="*70)
    
    # ãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–
    tester = Nutrition5kCompleteTest()
    
    # ãƒ†ã‚¹ãƒˆå¯¾è±¡ã®dish
    test_dishes = [
        "dish_1556572657",  # mmå˜ä½ã®ã‚µãƒ³ãƒ—ãƒ«
        # "dish_1556573514",  # 0.1mmå˜ä½ã®ã‚µãƒ³ãƒ—ãƒ«
        # å¿…è¦ã«å¿œã˜ã¦è¿½åŠ 
    ]
    
    results = []
    for dish_id in test_dishes:
        result = tester.test_single_dish(dish_id)
        if result:
            results.append(result)
    
    # çµ±è¨ˆã‚µãƒãƒªãƒ¼
    if results:
        print("\n" + "="*70)
        print("çµ±è¨ˆã‚µãƒãƒªãƒ¼")
        print("="*70)
        
        total_dishes = len(results)
        total_detections = sum(r['detections'] for r in results)
        total_masks = sum(r['masks'] for r in results)
        
        print(f"\nãƒ†ã‚¹ãƒˆæ•°: {total_dishes} dishes")
        print(f"æ¤œå‡ºç·æ•°: {total_detections} foods")
        print(f"ãƒã‚¹ã‚¯ç·æ•°: {total_masks} masks")
        
        # ä½“ç©ã®çµ±è¨ˆ
        gt_totals = [r['gt_volumes']['total_volume_mL'] for r in results if r['gt_volumes']]
        pred_totals = [r['pred_volumes']['total_volume_mL'] for r in results if r['pred_volumes']]
        
        if gt_totals and pred_totals:
            print(f"\nGTåˆè¨ˆä½“ç©:")
            print(f"  å¹³å‡: {np.mean(gt_totals):.1f} mL")
            print(f"  ç¯„å›²: {min(gt_totals):.1f} - {max(gt_totals):.1f} mL")
            
            print(f"\näºˆæ¸¬åˆè¨ˆä½“ç©:")
            print(f"  å¹³å‡: {np.mean(pred_totals):.1f} mL")
            print(f"  ç¯„å›²: {min(pred_totals):.1f} - {max(pred_totals):.1f} mL")
    
    print("\n" + "="*70)
    print("ãƒ†ã‚¹ãƒˆå®Œäº†")
    print("="*70)
    
    print("\nğŸ“Š é‡è¦ãªçŸ¥è¦‹:")
    print("1. QwenVL-2Bã«ã‚ˆã‚‹é£Ÿå“æ¤œå‡ºãŒä¿¯ç°ç”»åƒã§ã‚‚æ©Ÿèƒ½")
    print("2. SAM2.1ã«ã‚ˆã‚‹æ­£ç¢ºãªã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã§ä½“ç©ç²¾åº¦å‘ä¸Š")
    print("3. GTæ·±åº¦ã¨Depth Anything V2ã®æ¯”è¼ƒã«ã‚ˆã‚Šæ”¹å–„ç‚¹ãŒæ˜ç¢º")
    print("4. K_scale_factor=10.5ã®èª¿æ•´ã«ã‚ˆã‚Šç¾å®Ÿçš„ãªä½“ç©ã‚’ç®—å‡º")
    print("5. Fine-tuningã§ã•ã‚‰ãªã‚‹ç²¾åº¦å‘ä¸ŠãŒæœŸå¾…ã§ãã‚‹")


if __name__ == "__main__":
    main()